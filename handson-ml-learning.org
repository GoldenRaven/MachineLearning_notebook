# -*- org -*-
#+TITLE: 《机器学习实战》笔记
#+AUTHOR: GoldenRaven
#+DATE: <2020-02-27 Thu>
#+EMAIL: li.gaoyang@foxmail.com
# #+OPTIONS: num:t

#+BEGIN_COMMENT
#+BEGIN_SRC sh :session
bash crop-convert.bash
#+END_SRC

#+RESULTS:
| /home/ligy/Documents/MachineLearning_notebook/pdfs |       |            |         |           |          |           |    |       |           |
| PDFCROP                                            | 1.38, | 2012/11/02 | -       | Copyright | (c)      | 2002-2012 | by | Heiko | Oberdiek. |
| ==>                                                |     1 | page       | written | on        | `1.pdf'. |           |    |       |           |
| softmax.pdf                                        |       |            |         |           |          |           |    |       |           |

#+END_COMMENT
#+ATTR_HTML: :width 300
[[file:images/handson.jpg]]

这是我在学习Aurelien Geron的书籍《机器学习实战》时自己的总结，欢迎留言。
- [[file:chapt4.org][第四章 训练（线性）模型]]
- [[file:chapt5.org][第五章 支持向量机（SVM, support vector machine）]]
- [[file:summary_chap4_5.org][第四章和第五章总结]]
- [[file:chapt6.org][第六章 决策树（decision tree）]]
- 注意:
  + 对收入分层抽样，不能分太多层
  + 分层方法：除以1.5，向上取整；然后合并大于5的分类
  + 地理数据可视化，用其他相关属性作为颜色，和散点大小
  + 寻找与标签相关性高的属性，用 ~df.corr()['labels']~
  + 进一步考察高相关性属性的数据模式，并删除可能的错误数据
  + 尝试不同的属性组合，以找到高相关性特征
  + 将预测器与标签分离，因为可能不一定对它们使用相同的转换方式
  + 特征缩放（归一化、标准化），即同比缩放所有属性
  + 评估训练得的模型，对训练集求RMSE或MAE
  + 误差较大则拟合不足，可以
  + 误差过小？则用验证集来验证得到的模型，以检查是否过拟合
  + 交叉验证，可以sklearn的K-fold功能
  + 如果在验证集上得到的误差大则说明确实有过拟合，需要更换模型
  + 尝试多个模型以找到2-5个有效的模型，别花太多时间去调整超参数
  + 保存每个尝试过的模型，用pickel或sklearn的joblib
  + 训练集分数明显低于验证集分数，则过度拟合
  + 注意：目标值一般不进行绽放，并且只对训练集缩放
